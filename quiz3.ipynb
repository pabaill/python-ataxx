{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "states = ['sI', 'sN', 'sE']\n",
    "actions = ['aT', 'aA', 'aE']\n",
    "gamma = 0.9\n",
    "\n",
    "# Transition probabilities P(s' | s, a)\n",
    "transition_probabilities = {\n",
    "    ('sI', 'aT', 'sI'): 0.7,\n",
    "    ('sN', 'aT', 'sI'): 0.3,\n",
    "    ('sI', 'aA', 'sI'): 1.0,\n",
    "    ('sE', 'aE', 'sI'): 1.0,\n",
    "    ('sN', 'aT', 'sN'): 1.0,\n",
    "    ('sI', 'aA', 'sN'): 0.5,\n",
    "    ('sN', 'aA', 'sN'): 0.5,\n",
    "    ('sE', 'aE', 'sN'): 1.0,\n",
    "    ('sI', 'aT', 'sN'): 0.0,\n",
    "    ('sE', 'aE', 'sE'): 1.0,\n",
    "    ('sE', 'aT', 'sE'): 1.0,\n",
    "    ('sE', 'aA', 'sE'): 1.0,\n",
    "    ('sI', 'aT', 'sE'): 0.0,\n",
    "    ('sN', 'aT', 'sE'): 0.0,\n",
    "    ('sE', 'aT', 'sI'): 0.0\n",
    "}\n",
    "\n",
    "# Rewards R(s, a)\n",
    "rewards = {\n",
    "    ('sI', 'aA'): 1.1,\n",
    "    ('sI', 'aE'): 10.0,\n",
    "    ('sI', 'aT'): 0.0,\n",
    "    ('sN', 'aA'): 0.0,\n",
    "    ('sN', 'aE'): 0.0,\n",
    "    ('sN', 'aT'): -1.0,\n",
    "    ('sE', 'aA'): 0.0,\n",
    "    ('sE', 'aE'): 0.0,\n",
    "    ('sE', 'aT'): 0.0,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Calculate utility for given policy\n",
    "def calculate_utility(states, transition_probabilities, rewards, gamma, policy, tolerance=1e-6):\n",
    "    value_function = {state: 0.0 for state in states}\n",
    "    \n",
    "    while True:\n",
    "        delta = 0\n",
    "        new_value_function = value_function.copy()\n",
    "\n",
    "        for state in states:\n",
    "            action = policy[state]\n",
    "            new_value = 0\n",
    "\n",
    "            for next_state in states:\n",
    "                transition_prob = transition_probabilities.get((next_state, action, state), 0)\n",
    "                reward = rewards.get((state, action), 0)\n",
    "                new_value += transition_prob * (reward + gamma * value_function[next_state])\n",
    "            \n",
    "            new_value_function[state] = new_value\n",
    "\n",
    "            # Track the maximum change in value to check for convergence\n",
    "            delta = max(delta, abs(new_value_function[state] - value_function[state]))\n",
    "\n",
    "        # Check for convergence\n",
    "        if delta < tolerance:\n",
    "            break\n",
    "        \n",
    "        value_function = new_value_function\n",
    "\n",
    "    return value_function\n",
    "\n",
    "# Calculate maximum utility\n",
    "def calculate_max_utility(states, actions, transition_probabilities, rewards, gamma, tolerance=1e-6):\n",
    "    value_function = {state: 0.0 for state in states}\n",
    "    \n",
    "    while True:\n",
    "        delta = 0\n",
    "        for s in states:\n",
    "            v = value_function[s]\n",
    "            value_function[s] = max(sum(transition_probabilities.get((s_next, a, s),0) * \n",
    "                           (rewards.get((s, a),0) + gamma * value_function[s_next])\n",
    "                           for s_next in states) for a in actions)\n",
    "            delta = max(delta, abs(v - value_function[s]))\n",
    "        \n",
    "        # Check for convergence\n",
    "        if delta < tolerance:\n",
    "            break    \n",
    "\n",
    "    return value_function\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{('sI', 'aT', 'sI'): 0.7, ('sN', 'aT', 'sI'): 0.3, ('sI', 'aA', 'sI'): 1.0, ('sE', 'aE', 'sI'): 1.0, ('sN', 'aT', 'sN'): 1.0, ('sI', 'aA', 'sN'): 0.5, ('sN', 'aA', 'sN'): 0.5, ('sE', 'aE', 'sN'): 1.0, ('sI', 'aT', 'sN'): 0.0, ('sE', 'aE', 'sE'): 1.0, ('sE', 'aT', 'sE'): 1.0, ('sE', 'aA', 'sE'): 1.0, ('sI', 'aT', 'sE'): 0.0, ('sN', 'aT', 'sE'): 0.0, ('sE', 'aT', 'sI'): 0.0}\n",
      "Utility of each state under the policy:\n",
      "U(sI) = -7.30\n",
      "U(sN) = -10.00\n",
      "U(sE) = 0.00\n"
     ]
    }
   ],
   "source": [
    "policyQ2 = {\n",
    "    'sI': 'aE',\n",
    "    'sN': 'aE',\n",
    "    'sE': 'aE'\n",
    "}\n",
    "\n",
    "utility = calculate_utility(states, transition_probabilities, rewards, gamma, policyQ2)\n",
    "print(\"Utility of each state under the policy aE:\")\n",
    "for state, value in utility.items():\n",
    "    print(f\"U({state}) = {value:.2f}\")\n",
    "\n",
    "# calculate_max_utility(states, actions, transition_probabilities, rewards, gamma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Utility of each state under the policy aT:\n",
      "U(sI) = -7.30\n",
      "U(sN) = -10.00\n",
      "U(sE) = 0.00\n"
     ]
    }
   ],
   "source": [
    "policyQ3 = {\n",
    "    'sI': 'aT',\n",
    "    'sN': 'aT',\n",
    "    'sE': 'aT'\n",
    "}\n",
    "\n",
    "utility = calculate_utility(states, transition_probabilities, rewards, gamma, policyQ3)\n",
    "print(\"Utility of each state under the policy aT:\")\n",
    "for state, value in utility.items():\n",
    "    print(f\"U({state}) = {value:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Utility of each state under the policy aA:\n",
      "U(sI) = 11.00\n",
      "U(sN) = 9.00\n",
      "U(sE) = 0.00\n"
     ]
    }
   ],
   "source": [
    "policyQ4 = {\n",
    "    'sI': 'aA',\n",
    "    'sN': 'aA',\n",
    "    'sE': 'aA'\n",
    "}\n",
    "\n",
    "utility = calculate_utility(states, transition_probabilities, rewards, gamma, policyQ4)\n",
    "print(\"Utility of each state under the policy aA:\")\n",
    "for state, value in utility.items():\n",
    "    print(f\"U({state}) = {value:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Utility of each state (optimal):\n",
      "U(sI) = 11.00\n",
      "U(sN) = 9.00\n",
      "U(sE) = 0.00\n"
     ]
    }
   ],
   "source": [
    "# Q5\n",
    "max_utility = calculate_max_utility(states, actions, transition_probabilities, rewards, gamma)\n",
    "print(\"Utility of each state (optimal):\")\n",
    "for state, value in utility.items():\n",
    "    print(f\"U({state}) = {value:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal Policy:\n",
      "pi(sI) = aA\n",
      "pi(sN) = aA\n",
      "pi(sE) = aT\n"
     ]
    }
   ],
   "source": [
    "# Q6 / Q7\n",
    "policy = {}\n",
    "for s in states:\n",
    "    policy[s] = max(actions, key=lambda a: sum(transition_probabilities.get((s_next, a, s),0) * (rewards.get((s, a),0) + gamma * max_utility[s_next]) for s_next in states))\n",
    "print(\"Optimal Policy:\")\n",
    "for state, value in policy.items():\n",
    "    print(f\"pi({state}) = {value}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
